{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as any collaborators you worked with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLLABORATORS = \"me myself and I lol\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3c0e6f80c9a8d85d80baddc8df3890a0",
     "grade": false,
     "grade_id": "cell-7531378247537850",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "%matplotlib inline\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import the factorial function from scipy\n",
    "from scipy.special import factorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "57fe3d1a770d32fc71d10c52d47d5765",
     "grade": false,
     "grade_id": "cell-1055125360070174",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# HW 1:  Forms of Error\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "763bdcd61a173c57e8d82dcd9519ee2c",
     "grade": false,
     "grade_id": "cell-9681214437904696",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Question 1:  definition of errors\n",
    "\n",
    "**(a)**  [4 pts] Write a short python program to calculate and return, the absolute error, relative error and degree of decimal precision (as defined in class) given an object `f` and its approximation `F`.  Note, both `f` and `F` can be numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7c9bcb87e713e8ee4fb90ec822ed4d9f",
     "grade": false,
     "grade_id": "cell-a6ede65cf8ed685f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def errors(f,F):\n",
    "    \"\"\" calculate various measures of error of an object f and its approximation F\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    f:  numpy.array (or float)\n",
    "        array of true values\n",
    "        \n",
    "    F: numpy.array\n",
    "        array of approximate values\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    e: array of absolute errors\n",
    "    r: array of relative errors\n",
    "    p: integer array of precisions\n",
    "    \"\"\"\n",
    "    \n",
    "    f = numpy.asarray(f)\n",
    "    F = numpy.asarray(F)\n",
    "    e,r,p = numpy.array([]),numpy.array([]),numpy.array([])\n",
    "    \n",
    "    if f.ndim == 0:\n",
    "        e = numpy.abs(f - F)\n",
    "        r = e / numpy.abs(f)\n",
    "        p = int(-numpy.log10(r/5.))\n",
    "    \n",
    "    else:\n",
    "        for (f,F) in zip(f,F):\n",
    "            e = numpy.append(e,numpy.abs(f - F)) \n",
    "            r = numpy.append(r,numpy.abs(f - F) / numpy.abs(f))\n",
    "            p = numpy.append(p,int(-numpy.log10(numpy.abs(f - F) / numpy.abs(f) / 5.)))\n",
    "    \n",
    "\n",
    "#     # YOUR CODE HERE\n",
    "#     raise NotImplementedError()\n",
    "    return e, r, p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.81828459e-04 5.60989307e-05 5.36923188e-04] [1.03678896e-04 7.59216467e-06 2.67318315e-05] [4. 5. 5.]\n"
     ]
    }
   ],
   "source": [
    "x = [1., 2., 3.]\n",
    "f = numpy.exp(x)\n",
    "F = [ 2.718,  7.389,  20.085]\n",
    "e,r,p = errors(f,F)\n",
    "print(e,r,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f4295c880e6563c035f2e1176010b834",
     "grade": true,
     "grade_id": "cell-da2659b413c73ca7",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed scalar test\n",
      "passed array test\n"
     ]
    }
   ],
   "source": [
    "# Testing Cell (do not copy)\n",
    "\n",
    "# Test Simple Scalars\n",
    "e,r,p = errors(numpy.exp(1),2.72)\n",
    "answer = [0.0017181715409551046, 0.0006320799863232398, 3]\n",
    "numpy.testing.assert_allclose([e,r,p], answer)\n",
    "print('passed scalar test')\n",
    "\n",
    "# Test with array input\n",
    "x = [1., 2., 3.]\n",
    "f = numpy.exp(x)\n",
    "F = [ 2.718,  7.389,  20.085]\n",
    "e,r,p = errors(f,F)\n",
    "numpy.testing.assert_allclose(e,[2.81828459e-04, 5.60989307e-05, 5.36923188e-04])\n",
    "numpy.testing.assert_allclose(r,[1.03678896e-04, 7.59216467e-06, 2.67318315e-05])\n",
    "numpy.testing.assert_allclose(p,[4, 5, 5])\n",
    "print('passed array test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "39ee29a6b36ec47d40b72b71b941b0f2",
     "grade": false,
     "grade_id": "cell-bef4e3baf992ed93",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**(b)** [2 pts]  Use your routine to compare the absolute error, relative error and degree of precision for these two rational approximations of $\\pi$\n",
    "\n",
    "* $f = \\pi$ and $F = 22 / 7$\n",
    "* $f = \\pi$ and $F = 355 / 113$\n",
    "\n",
    "Which is more accurate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0012644892673496777 0.0004024994347707008 4\n",
      "2.667641894049666e-07 8.49136787674061e-08 7\n"
     ]
    }
   ],
   "source": [
    "f = numpy.pi\n",
    "F = 22 / 7\n",
    "e,r,p = errors(f,F)\n",
    "print(e,r,p)\n",
    "\n",
    "f = numpy.pi\n",
    "F = 355 / 113\n",
    "e,r,p = errors(f,F)\n",
    "print(e,r,p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "21b09b84adbced5a47c2142e0d7a29cd",
     "grade": true,
     "grade_id": "cell-4300360216304258",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "The second pair is more accurate, because the degree of precision of it is 7 and the first one is only 4\\\n",
    "Also, it has less absolute and relative error than the second one\n",
    "* $f = \\pi$ and $F = 355 / 113$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b5a1a21715793f4a9cd1d22da3c6fbd5",
     "grade": false,
     "grade_id": "cell-300ca517618db367",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**(c)** [6 pts] Write a python routine to find the most accurate $d$ digit rational approximation to $\\pi$. i.e. find\n",
    "two $d$ digit positive integers $m,n$ such that \n",
    "\n",
    "$$ F = \\frac{m}{n} \\sim \\pi$$\n",
    "\n",
    "(hint:  $355/113$ is the best 3-digit rational approximation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2fad6f779f0e38180756be9962ecfdda",
     "grade": false,
     "grade_id": "cell-4b8290252c936eec",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def rational_pi(d):\n",
    "    ''' Find the best rational approximation to pi ~ m/n where m and n are both d-digit positive integers\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    d: int\n",
    "        number of digits in both m and n\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    m,n: int\n",
    "        numerator and denominator of best d digit rational approximation to pi ~ m/n\n",
    "        \n",
    "    '''\n",
    "    e = numpy.pi\n",
    "    m = 0\n",
    "    n = 0\n",
    "    \n",
    "    if d != 0:    \n",
    "        for n_current in range(int(numpy.floor(10**d / numpy.pi)),int(10**(d - 1)) - 1,-1):\n",
    "            m_floor = int(numpy.floor(n_current * numpy.pi))\n",
    "            m_ceil = int(numpy.ceil(n_current * numpy.pi))\n",
    "            e_floor, r_floor, p_floor = errors(numpy.pi, m_floor / n_current)\n",
    "            e_ceil, r_ceil, p_ceil = errors(numpy.pi, m_ceil / n_current)\n",
    "            \n",
    "            if e_floor > e_ceil:\n",
    "                if e_ceil > e:\n",
    "                    pass\n",
    "                \n",
    "                else:\n",
    "                    e = e_ceil\n",
    "                    m = m_ceil\n",
    "                    n = n_current\n",
    "                    \n",
    "            else:\n",
    "                if e_floor > e:\n",
    "                    pass\n",
    "                \n",
    "                else:\n",
    "                    e = e_floor\n",
    "                    m = m_floor\n",
    "                    n = n_current\n",
    "            \n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    return m,n\n",
    "    \n",
    "#     # YOUR CODE HERE\n",
    "#     raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "29119ccc9d740a4e6317ed3dc57f6657",
     "grade": true,
     "grade_id": "cell-6568ef410973a577",
     "locked": true,
     "points": 6,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d=1: 3/1 = 3.0:\t e = 0.14159265358979312,\t, r = 0.04507034144862795,\t p= 2\n",
      "d=2: 44/14 = 3.142857142857143:\t e = 0.0012644892673496777,\t, r = 0.0004024994347707008,\t p= 4\n",
      "d=3: 355/113 = 3.1415929203539825:\t e = 2.667641894049666e-07,\t, r = 8.49136787674061e-08,\t p= 7\n",
      "d=4: 3195/1017 = 3.1415929203539825:\t e = 2.667641894049666e-07,\t, r = 8.49136787674061e-08,\t p= 7\n",
      "d=5: 99733/31746 = 3.1415926415926414:\t e = 1.1997151716514054e-08,\t, r = 3.818811997413258e-09,\t p= 9\n",
      "\n",
      "success!\n"
     ]
    }
   ],
   "source": [
    "# Testing Cell (do not copy)\n",
    "\n",
    "# print out best rational approximations and their errors  for d =1-5\n",
    "for d in range(1,6):\n",
    "    m,n = rational_pi(d)\n",
    "    e,r,p = errors(numpy.pi,m/n)\n",
    "    print('d={}: {}/{} = {}:\\t e = {},\\t, r = {},\\t p= {}'.format(d,m,n,m/n,e,r,p))\n",
    "    \n",
    "# Run assertion Tests\n",
    "numpy.testing.assert_allclose(rational_pi(2),(44, 14))\n",
    "numpy.testing.assert_allclose(rational_pi(3),(355, 113))\n",
    "print('\\nsuccess!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cabe33a4165802a8de9d6c0d6b322917",
     "grade": false,
     "grade_id": "cell-23707a8e710ca676",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**(d)** [6 pts] $F = n \\log(n) - n$ is Stirling's approximation to  $f = \\log(n!)$ for large values of $n$. \n",
    "Do the following\n",
    "\n",
    "* Make a plot showing the relative error and degree of decimal precision for $f$ and $F$ as a function of integer $n$\n",
    "\n",
    "* Estimate the smallest value of $n$ where Stirling's approximation is good to 4 decimal places of precision.  \n",
    "\n",
    "**Note**: If you use the `factorial` function imported from `scipy.special`, you will not be able to answer this question.  **Why?**  \n",
    "\n",
    "**Hint**: However there is another way to evaluate $\\log(n!)$ for integer $n$ that will work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6195fab472e4537966b7eba4a529a13b",
     "grade": true,
     "grade_id": "cell-a5639245c28a1642",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1452\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 2\n",
    "f = 0\n",
    "x = []\n",
    "y_error = []\n",
    "y_precision = []\n",
    "\n",
    "\n",
    "while True:\n",
    "    F = n * numpy.log(n) - n\n",
    "    f += numpy.log(n)\n",
    "    \n",
    "    e,r,p = errors(f,F)\n",
    "    \n",
    "    x.append(n)\n",
    "    y_error.append(r)\n",
    "    y_precision.append(p)\n",
    "    \n",
    "    if r < 5 * 10 ** -4:\n",
    "        print(n)\n",
    "        break;\n",
    "        \n",
    "    n += 1\n",
    "\n",
    "fig = plt.figure(figsize=(15,5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(x,y_error,'g',label='Relative Error')\n",
    "plt.xlabel(\"$n$\")\n",
    "plt.title(\"Relative Error for n\")\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(x,y_precision,'r',label='Degree of Precision')\n",
    "plt.xlabel(\"$n$\")\n",
    "plt.title(\"Degree of Precision for n\")\n",
    "plt.grid()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# # YOUR CODE HERE\n",
    "# raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c6321f16c18ce03a19fd25289b7d8ab4",
     "grade": true,
     "grade_id": "cell-dcc45d9028355b73",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "$$\n",
    "n = 1452\n",
    "$$\n",
    "\n",
    "the reason why I cannot solve this problem by using fractorial imported from ``scipy.special`` is:\n",
    "\n",
    "n is such a large number and the factorial cannot be calculated directly and easily."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "27bfc8b15912bb6e1cdfa2dfd103ced4",
     "grade": false,
     "grade_id": "cell-6968179660613369",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Question 2\n",
    "\n",
    "[4 pts] Given the Taylor polynomial expansions of two functions around $x=0$\n",
    "\n",
    "$$\\frac{1}{1-\\Delta x} = 1 + \\Delta x + \\Delta x^2 + \\Delta x^3 + O(\\Delta x^4)$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\\cosh \\Delta x = 1 + \\frac{\\Delta x^2}{2!} + \\frac{\\Delta x^4}{4!} + O(\\Delta x^6)$$\n",
    "\n",
    "calculate their sum and product as well as the order of approximation for the truncation error (i.e. determine the exponent that belongs in the $O$).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "77d458abae3cfa5157eca11bd346e444",
     "grade": true,
     "grade_id": "cell-8500724062567566",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "**Answer to Question 2**\n",
    "\n",
    "Set expansion below as the expanded form of $T_{N1}(x)$ for $N=3$ around $x_0 = 0$\n",
    "\n",
    "$$\\frac{1}{1-\\Delta x} = 1 + \\Delta x + \\Delta x^2 + \\Delta x^3 + O(\\Delta x^4)$$ \n",
    "\n",
    "Set expansion below as the expanded form of $T_{N2}(x)$ for $N=2$ around $x_0 = 0$\n",
    "\n",
    "$$\\cosh \\Delta x = 1 + \\frac{\\Delta x^2}{2!} + \\frac{\\Delta x^4}{4!} + O(\\Delta x^6)$$ \n",
    "\n",
    "So, from this two expansions we can easily know $T_{N1}(x)$ should be $$\\sum^N_{n=0} \\Delta x^{n}$$\n",
    "$T_{N2}(x)$ should be $$\\sum^N_{n=0} \\frac{\\Delta x^{2n}}{2n!}$$\n",
    "\n",
    "- **Sum** \n",
    "\n",
    "$$T_{Nsum}(x) = \\sum^N_{n=0} \\Delta x^{n} + \\sum^N_{n=0} \\frac{\\Delta x^{2n}}{2n!}\n",
    "              = \\sum^N_{n=0} (\\Delta x^{n} + \\frac{\\Delta x^{2n}}{2n!})\\\\\n",
    "              = 1 + \\Delta x + \\Delta x^2 + \\Delta x^3 + 1 + \\frac{\\Delta x^2}{2!} + \\frac{\\Delta x^4}{4!} + O(\\Delta x^4)\\\\\n",
    "              = 2+\\Delta x +\\frac{3 \\Delta x^2}{2}+  \\Delta x^3 +O(\\Delta x^4)\n",
    "              $$\n",
    "\n",
    "Since $\\Delta x^4$ and $\\Delta x^6$ are both small values, so the exponent that belongs in the $O$ should be $\\Delta x^4$, because the order k should be the minimum of (4,6), which should be 4\n",
    "\n",
    "\n",
    "- **Product**\n",
    "\n",
    "$$T_{Nproduct}(x) = \\sum^N_{n=0} \\Delta x^{n} * \\sum^N_{n=0} \\frac{\\Delta x^{2n}}{2n!}\\\\\n",
    "              = 1 * (1 + \\Delta x + \\Delta x^2 + \\Delta x^3) + \\frac{\\Delta x^2}{2!} * (1 + \\Delta x + \\Delta x^2 + \\Delta x^3) + \\frac{\\Delta x^4}{4!} * (1 + \\Delta x + \\Delta x^2 + \\Delta x^3) + O(\\Delta x^6) * (1 + \\Delta x + \\Delta x^2 + \\Delta x^3) + O(\\Delta x^4) * (1 + \\frac{\\Delta x^2}{2!} + \\frac{\\Delta x^4}{4!}) + O(\\Delta x^{6 + 4})\\\\\n",
    "              =1 * (1 + \\Delta x + \\Delta x^2 + \\Delta x^3) + \\frac{\\Delta x^2}{2!} * (1 + \\Delta x + \\Delta x^2 + \\Delta x^3) + \\frac{\\Delta x^4}{4!} * (1 + \\Delta x + \\Delta x^2 + \\Delta x^3) + O(\\Delta x^4)\\\\\n",
    "              = 1 + \\Delta x + \\frac{3 \\Delta x^2}{2} + \\frac{3 \\Delta x^3}{2} + O(\\Delta x^4)\n",
    "$$\n",
    "the exponent that belongs in the $O$ should be $\\Delta x^{4}$, which means the order equals to 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "237fcd7151c710b1c2fe86744794671b",
     "grade": false,
     "grade_id": "cell-5632471080286207",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Question 3:  The great Exp challenge...\n",
    "\n",
    "Here you will attempt to write a function to calculate $e^x$ using its Taylor polynomial approximation expanded around $x_0=0$\n",
    "\n",
    "$$e^x \\approx T_n(x) = 1 + x + \\frac{x^2}{2!} + \\frac{x^3}{3!} + \\cdots + \\frac{x^n}{n!}$$\n",
    "\n",
    "such that the relative error of $f=e^x$ and $F=T_n(x)$ is of order Machine epsilon ($\\epsilon_{machine}$) for  $x\\in[-50,50]$.  This problem is actually a bit of a stinker and takes a bit of thought (particularly for $x<0$).  But I'll work you through it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d16eac32cec2913a95095d153a7994b7",
     "grade": false,
     "grade_id": "cell-8186992197557199",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**(a)** [4 pts] Assume $x> 0$ and show that the upper bound on the *relative error*  at term $n$ \n",
    "\n",
    "$$r_n = \\frac{|e^x - T_n(x)|}{|e^x|}$$\n",
    "\n",
    "is given by\n",
    "\n",
    "$$r_n \\leq \\left | \\frac{x^{n+1}}{(n + 1)!} \\right |$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c066945aa96e6e08fcb676cf3b3e08f3",
     "grade": true,
     "grade_id": "cell-2747685663052674",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "**Answer to Question 3 (a)**\n",
    "\n",
    "Since $f=e^x$ and $F=T_N(x)$, by applying **Discretization Error of Taylor's Theorem**, $R_N(x)$ can be written as $\\frac{f^{(n+1)}(c) \\cdot (x - x_0)^{n+1}}{(n+1)!}$.\\\n",
    "Then, $T_N(x)$ can be written as $T_N(x)=f(x)-R_N(x)=e^x-\\frac{f^{(N+1)}(c) \\cdot (x - x_0)^{n+1}}{(n+1)!}$\\\n",
    "$r_n$ then can be written as $r_n = \\frac{|e^x - T_n(x)|}{|e^x|} =\\frac{|e^{(N+1)}(c) \\cdot (x - x_0)^{n+1}|}{|e^x(n+1)!|} $\\\n",
    "Since $0\\leq c\\leq x$, $e^c\\leq e^x$, $r_n = \\frac{|e^{(N+1)}(c) \\cdot (x - x_0)^{n+1}|}{|e^x(n+1)!|}   \\leq \\left | \\frac{x^{n+1}}{(n + 1)!} \\right | (x_0 = 0)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9a252bb988e5ae52a24a2e87dfe820b2",
     "grade": false,
     "grade_id": "cell-4678254376542691",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**(b)** [4 pts] Analytically show that for **large** $x\\gg1$ and $n$, $r_n \\leq \\epsilon_{\\text{machine}}$ implies that we need *approximately* $n > e \\cdot x$ terms in the series (where $e = \\text{exp}(1)$).\n",
    "\n",
    "*Hint* Use Stirling's approximation $log (n!) \\approx n~log~n - n$ (and then this problem is still a bit tricky)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8152aede9f1e1f429a231ee2b82df69c",
     "grade": true,
     "grade_id": "cell-4305745011657702",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "**Answer to Question 3(b)**\n",
    "\n",
    "According to $r_n \\leq \\epsilon_{machine}$, we can have something below:\n",
    "\n",
    "$$\n",
    "\\frac{x^{n+1}}{(n+1)!} \\leq \\epsilon_{machine}\n",
    "$$\n",
    "\n",
    "Since $\\epsilon_{machine}$ is a super small number, we then can eliminate it and change $\\leq$ to $<$\n",
    "\n",
    "$$\n",
    "x^{n+1}<(n+1)!\n",
    "$$\n",
    "\n",
    "Apply $log$ on both sides:\n",
    "\n",
    "$$\n",
    "(n+1)log(x) < (n+1)log(n+1)-(n+1)\n",
    "$$\n",
    "$$\n",
    "log(x) < log(n+1) - 1\n",
    "$$\n",
    "$$\n",
    "log(x) + 1 <log(n+1)\n",
    "$$\n",
    "$$\n",
    "log(x) + log(e) < log(n+1)\n",
    "$$\n",
    "\n",
    "For large values of $n$, $log(n+1) = log(n)$:\n",
    "$$\n",
    "log(x) + log(e) < log(n)\n",
    "$$\n",
    "$$\n",
    "log(e \\cdot x) < log(n)\n",
    "$$\n",
    "$$\n",
    "n > e \\cdot x\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a9cef1843dc0ae1deb7e6dbe5f77c33c",
     "grade": false,
     "grade_id": "cell-8048500717179941",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**(c)** [6 pts] Use this result to write a Python function that accurately approximates $e^x$ using $T_n(x)$ for scalar $x$ and returns both the estimate and the number of terms in the series.  Note that the testing tolerance will be $8 \\cdot \\epsilon_{\\text{machine}}$ over the range $x\\in[-50,50]$\n",
    "\n",
    "Make sure to document your code including expected inputs, outputs, and assumptions being made.\n",
    "\n",
    "Some Hints:\n",
    "* To make your life easier,  we will assume $x$ and $T_n(x)$ are just of type float (not arrays)\n",
    "* Think about how we evaluated polynomials efficiently in class\n",
    "* $T_n(x)$ for $x<0$ is a highly unstable alternating series with severe cancellation issues. However, there is a simple fix that will return accurate solutions independent of the sign of $x$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "80286c759520479af4ce906ac70f62e5",
     "grade": false,
     "grade_id": "cell-5914967225034965",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def Tn_exp(x):\n",
    "    \"\"\" Write a decent description here\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "        x: float\n",
    "            scalar value to approximate exp(x)\n",
    "    \"\"\"\n",
    "\n",
    "    assert(isinstance(x,float))\n",
    "    eps = numpy.finfo(float).eps\n",
    "      \n",
    "    use_inv = False\n",
    "    if x<0:\n",
    "        x = abs(x) \n",
    "        use_inv = True\n",
    "    \n",
    "    n = 1\n",
    "\n",
    "    while True:\n",
    "        \n",
    "        MAX_N = int(numpy.ceil(numpy.exp(1) * x)) + n\n",
    "        p = []\n",
    "\n",
    "        for n in range(MAX_N + 1):\n",
    "            p.append(1 / factorial(n)) \n",
    "        p.reverse()    \n",
    "\n",
    "        Tn = p[0]\n",
    "\n",
    "        for coefficient in p[1:]:\n",
    "            Tn = Tn * x + coefficient\n",
    "\n",
    "        if use_inv:\n",
    "            Tn = 1/Tn\n",
    "            r = numpy.abs((numpy.exp(-x) - Tn) / numpy.exp(-x))\n",
    "\n",
    "        else:\n",
    "            r = numpy.abs((numpy.exp(x) - Tn) / numpy.exp(x))\n",
    "\n",
    "\n",
    "        if r < (8.0 * eps):\n",
    "            break\n",
    "        \n",
    "        n += 1\n",
    "    \n",
    "\n",
    "#     # YOUR CODE HERE\n",
    "#     raise NotImplementedError()\n",
    "\n",
    "\n",
    "    return Tn, MAX_N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Tn_exp(x):\n",
    "    \"\"\" Write a decent description here\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "        x: float\n",
    "            scalar value to approximate exp(x)\n",
    "    \"\"\"\n",
    "\n",
    "    assert(isinstance(x,float))\n",
    "    eps = numpy.finfo(float).eps\n",
    "    \n",
    "    T_n = 1.0\n",
    "    MAX_N = int(2000 + int(abs(x) * 3))\n",
    "    \n",
    "    use_inv = False\n",
    "    if x<0:\n",
    "        x = abs(x) \n",
    "        use_inv = True\n",
    "    \n",
    "    for n in numpy.arange(MAX_N,0,-1):\n",
    "        T_n = T_n * x / n + 1.\n",
    "    \n",
    "    if use_inv:\n",
    "        T_n = 1.0/T_n\n",
    "    \n",
    "    Tn = T_n\n",
    "\n",
    "    return Tn, MAX_N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel free to test your code here and/or make a plot of errors\n",
    "\n",
    "x = numpy.linspace(-50, 50, 101)\n",
    "eps = numpy.finfo(float).eps\n",
    "\n",
    "answer = numpy.zeros(x.shape)\n",
    "N = numpy.zeros(x.shape)\n",
    "for i,xi in enumerate(x):\n",
    "    answer[i], N[i] = Tn_exp(xi)\n",
    "\n",
    "r = numpy.abs(answer - numpy.exp(x)) / numpy.abs(numpy.exp(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ab0f32ce185cc2c7955fb0d04d65f027",
     "grade": true,
     "grade_id": "cell-9688375319882602",
     "locked": true,
     "points": 6,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxmimum relative error = 3.10808965332734 eps_machine\n",
      "Success!\n"
     ]
    }
   ],
   "source": [
    "# Testing Cell (do not copy)\n",
    "\n",
    "x = numpy.linspace(-50, 50, 101)\n",
    "eps = numpy.finfo(float).eps\n",
    "tolerance = 8 * eps\n",
    "\n",
    "answer = numpy.zeros(x.shape)\n",
    "N = numpy.zeros(x.shape)\n",
    "for i,xi in enumerate(x):\n",
    "    answer[i], N[i] = Tn_exp(xi)\n",
    "r = numpy.abs(answer - numpy.exp(x)) / numpy.abs(numpy.exp(x))\n",
    "print('maxmimum relative error = {} eps_machine'.format(r.max()/eps))\n",
    "assert(numpy.all(r  < tolerance))\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2b1d4a353e51fbba1658f5a6968d1b42",
     "grade": false,
     "grade_id": "cell-c154452f653c5adc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**(d)** [4 pts] In ieee double precision,  the largest value of $x$ that has $e^x<$ `numpy.finfo(float).max` is about 709 (i.e. `numpy.log(numpy.finfo(float).max))`. \n",
    "\n",
    "* What is the relative error in units of machine epsilon for your routine and `f=numpy.exp(709)`\n",
    "* What is the relative error in units of machine epsilon for `F=numpy.exp(1)**709` and `f=numpy.exp(709)`\n",
    "\n",
    "Explain your results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a5a47ab9f08e7fe4764609703387ef9d",
     "grade": true,
     "grade_id": "cell-26e754d164cf2a3a",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "I wrote 2 piece of codes to generate the Tn and MAX_N\n",
    "The first one will find the Tn and MAX_N automatically starting from MAX_N = 1 and return the right answer.\n",
    "The second one also will do that but start from a prescribed MAX_N to 0 to get the right answer.\n",
    "Since the fisrt one will take so long on finding the right number of term of $709$, so I used the second one to get the answer to this question (d)\n",
    "\n",
    "Relative Error is: 11.483841610648803 machine epsilons.\\\n",
    "Relative Error is: 170.0702257577037 machine epsilons.\n",
    "\n",
    "Explaination:\n",
    "the reason why my routine's answer ss relatively smaller than `F=numpy.exp(1)**709` is I made the code find the term by itself. The reason why `F=numpy.exp(1)**709` is so large is $e \\times e ... \\times e$ for like 709 times will generate super great machine epsilon since the computer cannot represent $e \\times e ...$ exactly the same as the real $e^{709}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relative Error is: 11.483841610648803 machine epsilons.\n",
      "Relative Error is: 170.0702257577037 machine epsilons.\n"
     ]
    }
   ],
   "source": [
    "f = numpy.exp(709)\n",
    "F = Tn_exp(709.)[0]\n",
    "\n",
    "rel_error = abs(f-F)/abs(f)\n",
    "print(\"Relative Error is:\",rel_error/eps,\"machine epsilons.\")\n",
    "\n",
    "f = numpy.exp(709)\n",
    "F = numpy.exp(1)**709\n",
    "\n",
    "rel_error2 = abs(f - F) / abs(f)\n",
    "print(\"Relative Error is:\",rel_error2/eps, \"machine epsilons.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7acaa725abfd22229bddd35f652e4b57",
     "grade": false,
     "grade_id": "cell-aaa3ac7c64bd5868",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**(e)** **Extra Credit**\n",
    "\n",
    "[4 pts] Can you modify your routine for `Tn_exp(x)`) to approximate $e^x$ on the range $x\\in[-709, 709]$ to within 16 $\\epsilon_{machine}$?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9c184e65af5b8e5f46c673245638f9ef",
     "grade": false,
     "grade_id": "cell-28a21d2a7d0bda99",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def Tn_exp(x,tolerance):\n",
    "    \"\"\" Write a decent description here\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "        x: float\n",
    "            scalar value to approximate exp(x)\n",
    "    \"\"\"\n",
    "\n",
    "    assert(isinstance(x,float))\n",
    "    eps = numpy.finfo(float).eps\n",
    "    \n",
    "    T_n = 1.0\n",
    "    MAX_N = int(20 + int(abs(x) * 3))\n",
    "    \n",
    "    use_inv = False\n",
    "    if x<0:\n",
    "        x = abs(x) \n",
    "        use_inv = True\n",
    "    \n",
    "    for n in numpy.arange(MAX_N,0,-1):\n",
    "        T_n = T_n * x / n + 1.\n",
    "    \n",
    "    if use_inv:\n",
    "        T_n = 1.0/T_n\n",
    "    \n",
    "    Tn = T_n\n",
    "#         r = numpy.abs((numpy.exp(-x) - Tn) / numpy.exp(-x))\n",
    "#     else:\n",
    "#         r = numpy.abs((numpy.exp(x) - Tn) / numpy.exp(x))\n",
    "    \n",
    "#     while True:\n",
    "        \n",
    "#         MAX_N = int(numpy.ceil(numpy.exp(1) * x)) + n\n",
    "#         p = []\n",
    "\n",
    "#         for n in range(MAX_N + 1):\n",
    "#             p.append(1 / factorial(n)) \n",
    "#         p.reverse()    \n",
    "\n",
    "#         Tn = p[0]\n",
    "\n",
    "#         for coefficient in p[1:]:\n",
    "#             Tn = Tn * x + coefficient\n",
    "\n",
    "#         if use_inv:\n",
    "#             Tn = 1/Tn\n",
    "#             r = numpy.abs((numpy.exp(-x) - Tn) / numpy.exp(-x))\n",
    "\n",
    "#         else:\n",
    "#             r = numpy.abs((numpy.exp(x) - Tn) / numpy.exp(x))\n",
    "\n",
    "#         if r < tolerance:\n",
    "#             break\n",
    "        \n",
    "#         n += 1\n",
    "    \n",
    "    \n",
    "\n",
    "#     # YOUR CODE HERE\n",
    "#     raise NotImplementedError()\n",
    "\n",
    "\n",
    "    return Tn, MAX_N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxmimum relative error = 14.198921216203827 eps_machine\n",
      "Success!\n"
     ]
    }
   ],
   "source": [
    "x = numpy.linspace(-709, 709, 101)\n",
    "tolerance = 16 * eps\n",
    "\n",
    "answer = numpy.zeros(x.shape)\n",
    "N = numpy.zeros(x.shape)\n",
    "for i,xi in enumerate(x):\n",
    "    answer[i], N[i] = Tn_exp(xi, tolerance=tolerance)\n",
    "r = numpy.abs(answer - numpy.exp(x)) / numpy.abs(numpy.exp(x))\n",
    "print('maxmimum relative error = {} eps_machine'.format(r.max()/eps))\n",
    "assert(numpy.all(r  < tolerance))\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "47c964bd17be30e90d2a8b03d580466c",
     "grade": true,
     "grade_id": "cell-96883753198883843",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxmimum relative error = 14.198921216203827 eps_machine\n",
      "Success!\n"
     ]
    }
   ],
   "source": [
    "x = numpy.linspace(-709, 709, 101)\n",
    "tolerance = 16 * eps\n",
    "\n",
    "answer = numpy.zeros(x.shape)\n",
    "N = numpy.zeros(x.shape)\n",
    "for i,xi in enumerate(x):\n",
    "    answer[i], N[i] = Tn_exp(xi, tolerance=tolerance)\n",
    "r = numpy.abs(answer - numpy.exp(x)) / numpy.abs(numpy.exp(x))\n",
    "print('maxmimum relative error = {} eps_machine'.format(r.max()/eps))\n",
    "assert(numpy.all(r  < tolerance))\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0ea70a0549b8738a4ff278bbe58f20df",
     "grade": false,
     "grade_id": "cell-6605000347660435",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Question 4\n",
    "\n",
    "Consider a computing system that uses deoxyribonucleic acid (DNA) to store information.  Given that DNA is formed from the 4 nucleobases adenine, cytosine, guanine, and thymine (uracil is only found in RNA) let us assume that our storage of numbers will be base 4.  Answer the following questions based on this assuming that we have $p=3$ for the mantissa and the exponent $E \\in [-3, 3]$ (and we'll pretend DNA has a sign bit...chirality?)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c13ca513b18f26ed2af616dd50206047",
     "grade": false,
     "grade_id": "cell-9339658002746268",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**(a)** [4 pts] How many numbers can we represent with this floating point system (assume it's normalized)?  What are the underflow and overflow limits? What is machine Epsilon?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b0255974fb370e1c331638d41f074ddf",
     "grade": true,
     "grade_id": "cell-623b625975f5da41",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "Since our storage of numbers will be base 4, Mantissa equals to 3 and exponent is from -3 to 3, our number should firstly be a quaternary number that has a form of $-1^{S} \\times M \\times Base^{E} = \\pm d_1 . d_2 d_3 d_4 \\ldots d_p \\times Base^E$\\\n",
    "After substituting the given info in this form, we can get the range of this floating point system: $ \\pm (3 \\times 4^{-3}... 3 \\times 4^{3})$\\\n",
    "So the total number of this chiral floating point system is: $2 \\times 3 \\times 4 \\times 4 \\times 7 + 1 = 673$\\\n",
    "The underflow limit is: $ -1.00 \\times 4^{-3} = -0.015625$\\\n",
    "The overflow limit is: $3.33 \\times 4^{3} = 192$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "29c7fc5ca0808f62a6b35897f3fbbe87",
     "grade": false,
     "grade_id": "cell-9339658dsfsdf46268",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**(b)** [4pts] Graphically show how the numbers on the decimal real line are distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b95cccb5e3723bc4ebd7a1a10500f39a",
     "grade": true,
     "grade_id": "cell-4c6d3ae47566d1f1",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "d_1_values = [1,2,3]\n",
    "d_2_values = [0,1,2,3]\n",
    "d_3_values = [0,1,2,3]\n",
    "E_values = [3,2,1,0,-1,-2,-3]\n",
    "\n",
    "fig = plt.figure(figsize=(10.0, 1.0))\n",
    "\n",
    "\n",
    "for E in E_values:\n",
    "    for d1 in d_1_values:\n",
    "        for d2 in d_2_values:\n",
    "            for d3 in d_3_values:\n",
    "                plt.plot( (d1 + d2 * 4 ** (-1) + d3 * 4 ** (-2)) * 4**E, 0.0, 'r+', markersize=20)\n",
    "                plt.plot(-(d1 + d2 * 4 ** (-1) + d3 * 4 ** (-2)) * 4**E, 0.0, 'r+', markersize=20)\n",
    "            \n",
    "plt.plot(0.0, 0.0, '+', markersize=20)\n",
    "plt.plot([-10, 10], [0.0, 0.0], 'k')\n",
    "\n",
    "plt.title(\"Distribution of Values $[-10,10]$\")\n",
    "plt.yticks([])\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"\")\n",
    "plt.xlim([-10,10])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fab0fc5f3065c300023b60719c30cb3b",
     "grade": false,
     "grade_id": "cell-93396552502746268",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**(c)** [4 pts] How many more numbers can we store in $N$ base-pairs (base 4) versus $N$ bits (base 2) where the mantissa and exponent are the same relative length (e.g.  p=3, and $E\\in[-3,3]$ for both problems)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "16825fa4b75b7fc34d854b1653fe64b8",
     "grade": true,
     "grade_id": "cell-6de5d8dbf91c5ff7",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "* base 2:\\\n",
    "$d_1 = [1,2,3]\\\\\n",
    "d_2 = [0,1,2,3]\\\\\n",
    "d_3 = [0,1,2,3]\\\\\n",
    "E = [-3,-2,-1,0,1,2,3]$\n",
    "So, the total number will be $2 \\times 1 \\times 2 \\times 2 \\times 7 + 1 = 57$\n",
    "\n",
    "* base 4:\\\n",
    "$2 \\times 3 \\times 4 \\times 4 \\times 7 + 1 = 673$\n",
    "\n",
    "* difference:\\\n",
    "$673 - 57 = 616$\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
